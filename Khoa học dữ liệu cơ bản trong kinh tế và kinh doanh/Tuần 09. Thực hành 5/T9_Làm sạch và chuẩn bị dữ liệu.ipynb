{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bc3a71",
   "metadata": {},
   "source": [
    "# Phần 1: Xử lý dữ liệu thiếu (Missing Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d58485a",
   "metadata": {},
   "source": [
    "## Bài 1.1 - Phát hiện dữ liệu thiếu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35121738",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame với dữ liệu nhân viên công ty có các cột: `TenNV`, `Tuoi`, `Luong`, `PhongBan`, `KinhNghiem` với một số giá trị thiếu (None/NaN).\n",
    "\n",
    "2. Sử dụng các phương thức `isna()`, `isnull()`, `notna()` để phát hiện dữ liệu thiếu.\n",
    "\n",
    "3. Đếm số lượng dữ liệu thiếu theo từng cột và tổng số dữ liệu thiếu trong toàn bộ DataFrame.\n",
    "\n",
    "4. Tìm các hàng có ít nhất 2 giá trị thiếu và hiển thị chúng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tạo DataFrame với dữ liệu thiếu\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],\n",
    "    'Luong': [15000000, 18000000, None, 22000000, None],\n",
    "    'PhongBan': ['IT', None, 'Marketing', 'IT', 'HR'],\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "print(\"DataFrame nhân viên với dữ liệu thiếu:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "# 2. Phát hiện dữ liệu thiếu\n",
    "\n",
    "# 3. Đếm số lượng dữ liệu thiếu\n",
    "\n",
    "# 4. Tìm các hàng có ít nhất 2 giá trị thiếu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0cc45",
   "metadata": {},
   "source": [
    "## Bài 1.2 - Xử lý dữ liệu thiếu bằng dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60280879",
   "metadata": {},
   "source": [
    "1. Sử dụng DataFrame từ bài 1.1, áp dụng phương thức `dropna()` với các tham số khác nhau:\n",
    "   - Loại bỏ tất cả hàng có ít nhất 1 giá trị thiếu (`how='any'`)\n",
    "   - Loại bỏ hàng chỉ khi tất cả giá trị đều thiếu (`how='all'`)\n",
    "   - Loại bỏ cột có dữ liệu thiếu (`axis=1`)\n",
    "\n",
    "2. Áp dụng `dropna()` chỉ trên một số cột cụ thể (`subset`).\n",
    "\n",
    "3. So sánh kích thước DataFrame trước và sau khi áp dụng từng phương pháp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tạo DataFrame với dữ liệu thiếu\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],\n",
    "    'Luong': [15000000, 18000000, None, 22000000, None],\n",
    "    'PhongBan': ['IT', None, 'Marketing', 'IT', 'HR'],\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "\n",
    "# Sử dụng DataFrame từ bài 1.1\n",
    "print(\"DataFrame gốc:\")\n",
    "print(df_nhanvien)\n",
    "print(f\"Kích thước gốc: {df_nhanvien.shape}\")\n",
    "\n",
    "# 1. Loại bỏ hàng có ít nhất 1 giá trị thiếu\n",
    "\n",
    "# 2. Loại bỏ hàng chỉ khi tất cả giá trị đều thiếu\n",
    "\n",
    "# 3. Loại bỏ cột có dữ liệu thiếu\n",
    "\n",
    "# 4. Loại bỏ dựa trên subset của các cột"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2eec8c",
   "metadata": {},
   "source": [
    "## Bài 1.3 - Thay thế dữ liệu thiếu bằng fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b67a4",
   "metadata": {},
   "source": [
    "1. Sử dụng DataFrame từ bài 1.1, thay thế dữ liệu thiếu bằng các phương pháp khác nhau:\n",
    "   - Thay thế bằng giá trị cố định (0 cho số, \"Không xác định\" cho chuỗi)\n",
    "   - Thay thế bằng giá trị trung bình (mean) cho các cột số\n",
    "   - Thay thế bằng giá trị trung vị (median) cho các cột số\n",
    "   - Thay thế bằng giá trị phổ biến nhất (mode) cho các cột phân loại\n",
    "\n",
    "2. Tạo một DataFrame khác có dữ liệu chuỗi thời gian và áp dụng forward fill và backward fill.\n",
    "\n",
    "3. So sánh kết quả của các phương pháp thay thế khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70a1b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tạo DataFrame với dữ liệu thiếu\n",
    "data_nhanvien = {\n",
    "    'TenNV': ['Nguyễn Văn A', 'Trần Thị B', 'Lê Văn C', 'Phạm Thị D', 'Hoàng Văn E'],\n",
    "    'Tuoi': [25, None, 30, 28, None],\n",
    "    'Luong': [15000000, 18000000, None, 22000000, None],\n",
    "    'PhongBan': ['IT', None, 'Marketing', 'IT', 'HR'],\n",
    "    'KinhNghiem': [2, 5, None, 7, 1]\n",
    "}\n",
    "\n",
    "df_nhanvien = pd.DataFrame(data_nhanvien)\n",
    "\n",
    "# 1. Thay thế bằng các phương pháp khác nhau\n",
    "print(\"DataFrame gốc:\")\n",
    "print(df_nhanvien)\n",
    "\n",
    "# Thay thế bằng giá trị cố định\n",
    "\n",
    "# Thay thế bằng mean cho cột số\n",
    "\n",
    "# Thay thế bằng median cho cột số\n",
    "\n",
    "# Thay thế bằng mode cho cột phân loại\n",
    "\n",
    "# 2. Tạo DataFrame chuỗi thời gian để demo forward/backward fill\n",
    "data_timeseries = {\n",
    "    'ngay': pd.date_range('2024-01-01', periods=7, freq='D'),\n",
    "    'gia_co_phieu': [100, None, 105, None, None, 110, 115],\n",
    "    'khoi_luong': [1000, 1200, None, 1500, None, None, 1800]\n",
    "}\n",
    "\n",
    "df_timeseries = pd.DataFrame(data_timeseries)\n",
    "print(\"\\nDataFrame chuỗi thời gian:\")\n",
    "print(df_timeseries)\n",
    "\n",
    "# Forward fill và backward fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0aea84",
   "metadata": {},
   "source": [
    "# Phần 2: Xử lý dữ liệu trùng lặp (Duplicate Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca43bab",
   "metadata": {},
   "source": [
    "## Bài 2.1 - Phát hiện và xử lý dữ liệu trùng lặp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f6f630",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame về thông tin khách hàng có chứa dữ liệu trùng lặp với các cột: `TenKH`, `Tuoi`, `ThanhPho`, `SoDienThoai`.\n",
    "\n",
    "2. Sử dụng phương thức `duplicated()` để phát hiện các hàng trùng lặp.\n",
    "\n",
    "3. Đếm tổng số hàng trùng lặp và hiển thị các hàng bị trùng lặp.\n",
    "\n",
    "4. Sử dụng `drop_duplicates()` để loại bỏ dữ liệu trùng lặp với các tham số khác nhau:\n",
    "   - Giữ lại bản ghi đầu tiên (`keep='first'`)\n",
    "   - Giữ lại bản ghi cuối cùng (`keep='last'`)\n",
    "   - Loại bỏ tất cả bản ghi trùng lặp (`keep=False`)\n",
    "\n",
    "5. Xử lý trùng lặp dựa trên một số cột cụ thể (`subset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefe7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Tạo DataFrame có dữ liệu trùng lặp\n",
    "data_khachhang = {\n",
    "    'TenKH': ['Nguyễn Văn A', 'Trần Thị B', 'Nguyễn Văn A', 'Lê Văn C', 'Trần Thị B', 'Phạm Thị D'],\n",
    "    'Tuoi': [25, 30, 25, 35, 30, 28],\n",
    "    'ThanhPho': ['Hà Nội', 'TP.HCM', 'Hà Nội', 'Đà Nẵng', 'TP.HCM', 'Hà Nội'],\n",
    "    'SoDienThoai': ['0123456789', '0987654321', '0123456789', '0111222333', '0987654321', '0999888777']\n",
    "}\n",
    "\n",
    "df_khachhang = pd.DataFrame(data_khachhang)\n",
    "print(\"DataFrame khách hàng có dữ liệu trùng lặp:\")\n",
    "print(df_khachhang)\n",
    "\n",
    "# 2. Phát hiện dữ liệu trùng lặp\n",
    "\n",
    "# 3. Đếm và hiển thị các hàng trùng lặp\n",
    "\n",
    "# 4. Loại bỏ dữ liệu trùng lặp với các tham số khác nhau\n",
    "\n",
    "# 5. Xử lý trùng lặp dựa trên subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c323cc",
   "metadata": {},
   "source": [
    "# Phần 3: Biến đổi và chuẩn hóa dữ liệu (Data Transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0afff8",
   "metadata": {},
   "source": [
    "## Bài 3.1 - Min-Max Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c468fe",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame về thông tin bất động sản với các cột: `DienTich` (m²), `Gia` (triệu VND), `SoPhong`, `TuoiNha` (năm).\n",
    "\n",
    "2. Áp dụng Min-Max Normalization bằng công thức thủ công cho cột `Gia`.\n",
    "\n",
    "3. Sử dụng `MinMaxScaler` từ scikit-learn để chuẩn hóa tất cả các cột số.\n",
    "\n",
    "4. So sánh kết quả trước và sau khi chuẩn hóa bằng cách vẽ biểu đồ hoặc thống kê mô tả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c887da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tạo DataFrame về bất động sản\n",
    "data_batdongsan = {\n",
    "    'DienTich': [50, 80, 120, 200, 300],\n",
    "    'Gia': [2000, 3500, 5000, 8000, 12000],  # triệu VND\n",
    "    'SoPhong': [2, 3, 4, 5, 6],\n",
    "    'TuoiNha': [5, 10, 15, 20, 25]  # năm\n",
    "}\n",
    "\n",
    "df_batdongsan = pd.DataFrame(data_batdongsan)\n",
    "print(\"DataFrame bất động sản gốc:\")\n",
    "print(df_batdongsan)\n",
    "print(\"\\nThống kê mô tả:\")\n",
    "print(df_batdongsan.describe())\n",
    "\n",
    "# 2. Min-Max Normalization thủ công cho cột Gia\n",
    "\n",
    "# 3. Sử dụng MinMaxScaler cho tất cả cột số\n",
    "\n",
    "# 4. So sánh kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bb225",
   "metadata": {},
   "source": [
    "## Bài 3.2 - Z-score Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802714f",
   "metadata": {},
   "source": [
    "1. Sử dụng DataFrame từ bài 3.1, áp dụng Z-score Standardization bằng công thức thủ công cho cột `DienTich`.\n",
    "\n",
    "2. Sử dụng `StandardScaler` từ scikit-learn để chuẩn hóa tất cả các cột số.\n",
    "\n",
    "3. Kiểm tra xem dữ liệu sau standardization có mean ≈ 0 và std ≈ 1 không.\n",
    "\n",
    "4. So sánh kết quả giữa Min-Max Normalization và Z-score Standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea35bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Tạo DataFrame về bất động sản\n",
    "data_batdongsan = {\n",
    "    'DienTich': [50, 80, 120, 200, 300],\n",
    "    'Gia': [2000, 3500, 5000, 8000, 12000],  # triệu VND\n",
    "    'SoPhong': [2, 3, 4, 5, 6],\n",
    "    'TuoiNha': [5, 10, 15, 20, 25]  # năm\n",
    "}\n",
    "\n",
    "df_batdongsan = pd.DataFrame(data_batdongsan)\n",
    "# 1. Z-score Standardization thủ công cho cột DienTich\n",
    "print(\"DataFrame gốc:\")\n",
    "print(df_batdongsan)\n",
    "\n",
    "# Tính Z-score thủ công cho DienTich\n",
    "\n",
    "# 2. Sử dụng StandardScaler cho tất cả cột\n",
    "\n",
    "# 3. Kiểm tra mean và std\n",
    "\n",
    "# 4. So sánh Min-Max vs Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f4168",
   "metadata": {},
   "source": [
    "## Bài 3.3 - Robust Scaler và xử lý Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de9923",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame mới có chứa outliers (giá trị ngoại lai) trong cột `Gia`.\n",
    "\n",
    "2. So sánh hiệu quả của 3 phương pháp scaling khi có outliers:\n",
    "   - MinMaxScaler\n",
    "   - StandardScaler  \n",
    "   - RobustScaler\n",
    "\n",
    "3. Sử dụng `RobustScaler` để xử lý dữ liệu có outliers.\n",
    "\n",
    "4. Vẽ biểu đồ hoặc thống kê để thấy rõ sự khác biệt giữa các phương pháp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6d2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Tạo DataFrame có outliers\n",
    "data_outliers = {\n",
    "    'DienTich': [50, 80, 120, 200, 300, 95],\n",
    "    'Gia': [2000, 3500, 5000, 8000, 50000, 4200],  # 50000 là outlier\n",
    "    'SoPhong': [2, 3, 4, 5, 8, 3],  # 8 là outlier\n",
    "    'TuoiNha': [5, 10, 15, 20, 25, 12]\n",
    "}\n",
    "\n",
    "df_outliers = pd.DataFrame(data_outliers)\n",
    "print(\"DataFrame có outliers:\")\n",
    "print(df_outliers)\n",
    "print(\"\\nThống kê mô tả:\")\n",
    "print(df_outliers.describe())\n",
    "\n",
    "# 2. So sánh 3 phương pháp scaling\n",
    "\n",
    "# 3. Sử dụng RobustScaler\n",
    "\n",
    "# 4. Phân tích kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579ee60",
   "metadata": {},
   "source": [
    "# Phần 4: Xử lý chuỗi ký tự (String Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f0fdc",
   "metadata": {},
   "source": [
    "## Bài 4.1 - Xử lý chuỗi ký tự cơ bản"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feedbde",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame về thông tin sản phẩm với các cột: `TenSP`, `MoTa`, `DanhMuc` có dữ liệu chuỗi không đồng nhất (có khoảng trắng thừa, chữ hoa/thường khác nhau).\n",
    "\n",
    "2. Sử dụng các phương thức xử lý chuỗi cơ bản:\n",
    "   - `.str.lower()`, `.str.upper()`, `.str.title()`\n",
    "   - `.str.strip()` để loại bỏ khoảng trắng\n",
    "   - `.str.replace()` để thay thế ký tự\n",
    "   - `.str.len()` để tính độ dài chuỗi\n",
    "\n",
    "3. Tìm kiếm và lọc dữ liệu bằng:\n",
    "   - `.str.contains()` để tìm sản phẩm chứa từ khóa\n",
    "   - `.str.startswith()` và `.str.endswith()`\n",
    "\n",
    "4. Tách chuỗi bằng `.str.split()` để tách danh mục sản phẩm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1bf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Tạo DataFrame với dữ liệu chuỗi không đồng nhất\n",
    "data_sanpham = {\n",
    "    'TenSP': ['  iPhone 15 Pro  ', 'samsung galaxy s23', 'XIAOMI Mi 13', '  MacBook Air M2  ', 'dell XPS 13'],\n",
    "    'MoTa': ['Điện thoại thông minh cao cấp', '  Smartphone Android mới nhất  ', 'ĐIỆN THOẠI XIAOMI GIÁ RẺ', 'Laptop Apple siêu mỏng', '  máy tính xách tay Dell  '],\n",
    "    'DanhMuc': ['Điện thoại/Apple', 'Điện thoại/Samsung', 'Điện thoại/Xiaomi', 'Laptop/Apple', 'Laptop/Dell']\n",
    "}\n",
    "\n",
    "df_sanpham = pd.DataFrame(data_sanpham)\n",
    "print(\"DataFrame sản phẩm với dữ liệu chuỗi không đồng nhất:\")\n",
    "print(df_sanpham)\n",
    "\n",
    "# 2. Xử lý chuỗi cơ bản\n",
    "\n",
    "# 3. Tìm kiếm và lọc dữ liệu\n",
    "\n",
    "# 4. Tách chuỗi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b145862",
   "metadata": {},
   "source": [
    "## Bài 4.2 - Regular Expressions (Regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f1a65",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame chứa thông tin liên hệ khách hàng với cột `ThongTin` chứa địa chỉ email, số điện thoại, website.\n",
    "\n",
    "2. Sử dụng regex để trích xuất:\n",
    "   - Địa chỉ email bằng pattern cho email\n",
    "   - Số điện thoại Việt Nam (các định dạng khác nhau)\n",
    "   - Website/URL\n",
    "\n",
    "3. Làm sạch và chuẩn hóa số điện thoại về định dạng thống nhất.\n",
    "\n",
    "4. Tạo các cột riêng biệt cho email, số điện thoại, website đã được trích xuất."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Tạo DataFrame với thông tin liên hệ\n",
    "data_lienhe = {\n",
    "    'KhachHang': ['Công ty A', 'Khách hàng B', 'Doanh nghiệp C', 'Cá nhân D', 'Tổ chức E'],\n",
    "    'ThongTin': [\n",
    "        'Email: info@congtyA.com, SĐT: 0123-456-789, Website: https://congtyA.com',\n",
    "        'Liên hệ: khachhangB@gmail.com hoặc gọi +84 987 654 321',\n",
    "        'Hotline: (028) 3825-7863, web: www.doanhnghiepC.vn, mail: contact@doanhnghiepC.vn',\n",
    "        'Phone: 0987.654.321, email: canhanD@yahoo.com',\n",
    "        'Tel: 1900-1234, site: https://tochucE.org.vn, email: admin@tochucE.org.vn'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_lienhe = pd.DataFrame(data_lienhe)\n",
    "print(\"DataFrame thông tin liên hệ:\")\n",
    "print(df_lienhe)\n",
    "\n",
    "# 2. Trích xuất thông tin bằng regex\n",
    "\n",
    "# 3. Chuẩn hóa số điện thoại\n",
    "\n",
    "# 4. Tạo các cột riêng biệt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f8a2a",
   "metadata": {},
   "source": [
    "# Phần 5: Xử lý dữ liệu phân loại (Categorical Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44f937",
   "metadata": {},
   "source": [
    "## Bài 5.1 - Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb93869",
   "metadata": {},
   "source": [
    "1. Tạo một DataFrame về đánh giá khóa học với các cột: `TenKhoaHoc`, `TrinhDo` (Cơ bản, Trung cấp, Nâng cao), `XepLoai` (Kém, Trung bình, Khá, Giỏi, Xuất sắc), `NgonNgu`.\n",
    "\n",
    "2. Áp dụng Label Encoding cho:\n",
    "   - Cột `TrinhDo` (có thứ tự tự nhiên)\n",
    "   - Cột `XepLoai` (có thứ tự tự nhiên)\n",
    "   - Cột `NgonNgu` (không có thứ tự tự nhiên)\n",
    "\n",
    "3. So sánh kết quả Label Encoding với pandas Category và thứ tự tùy chỉnh cho dữ liệu ordinal.\n",
    "\n",
    "4. Phân tích ưu/nhược điểm của Label Encoding cho từng loại dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas \n",
    "\n",
    "# 1. Tạo DataFrame về đánh giá khóa học\n",
    "data_khoahoc = {\n",
    "    'TenKhoaHoc': ['Python cơ bản', 'Java nâng cao', 'SQL trung cấp', 'HTML cơ bản', 'React nâng cao'],\n",
    "    'TrinhDo': ['Cơ bản', 'Nâng cao', 'Trung cấp', 'Cơ bản', 'Nâng cao'],\n",
    "    'XepLoai': ['Khá', 'Xuất sắc', 'Giỏi', 'Trung bình', 'Giỏi'],\n",
    "    'NgonNgu': ['Python', 'Java', 'SQL', 'HTML', 'JavaScript']\n",
    "}\n",
    "\n",
    "df_khoahoc = pd.DataFrame(data_khoahoc)\n",
    "print(\"DataFrame đánh giá khóa học:\")\n",
    "print(df_khoahoc)\n",
    "\n",
    "# 2. Áp dụng Label Encoding\n",
    "\n",
    "# 3. Sử dụng pandas Category với thứ tự tùy chỉnh\n",
    "\n",
    "# 4. Phân tích kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a79a5b",
   "metadata": {},
   "source": [
    "## Bài 5.2 - One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9067ebbc",
   "metadata": {},
   "source": [
    "1. Sử dụng DataFrame từ bài 5.1, áp dụng One-Hot Encoding cho các cột phân loại nominal (không có thứ tự tự nhiên).\n",
    "\n",
    "2. So sánh hai phương pháp One-Hot Encoding:\n",
    "   - Sử dụng `pd.get_dummies()`\n",
    "   - Sử dụng `OneHotEncoder` từ scikit-learn\n",
    "\n",
    "3. Xử lý tham số `drop_first=True` để tránh multicollinearity.\n",
    "\n",
    "4. So sánh kích thước DataFrame trước và sau One-Hot Encoding và phân tích ưu/nhược điểm.\n",
    "\n",
    "5. Kết hợp cả Label Encoding và One-Hot Encoding trong cùng một DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas \n",
    "\n",
    "# 1. Tạo DataFrame về đánh giá khóa học\n",
    "data_khoahoc = {\n",
    "    'TenKhoaHoc': ['Python cơ bản', 'Java nâng cao', 'SQL trung cấp', 'HTML cơ bản', 'React nâng cao'],\n",
    "    'TrinhDo': ['Cơ bản', 'Nâng cao', 'Trung cấp', 'Cơ bản', 'Nâng cao'],\n",
    "    'XepLoai': ['Khá', 'Xuất sắc', 'Giỏi', 'Trung bình', 'Giỏi'],\n",
    "    'NgonNgu': ['Python', 'Java', 'SQL', 'HTML', 'JavaScript']\n",
    "}\n",
    "\n",
    "df_khoahoc = pd.DataFrame(data_khoahoc)\n",
    "print(\"DataFrame đánh giá khóa học:\")\n",
    "print(df_khoahoc)\n",
    "\n",
    "# 2. One-Hot Encoding bằng pd.get_dummies()\n",
    "\n",
    "# 3. One-Hot Encoding bằng sklearn OneHotEncoder\n",
    "\n",
    "# 4. So sánh kích thước và phân tích\n",
    "\n",
    "# 5. Kết hợp Label Encoding và One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5b4a1a",
   "metadata": {},
   "source": [
    "# Phần 6: Bài tập tổng hợp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067b799",
   "metadata": {},
   "source": [
    "## Bài 6.1 - Dự án làm sạch dữ liệu hoàn chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6eb8b",
   "metadata": {},
   "source": [
    "**Mô tả:** Bạn được cung cấp dữ liệu khảo sát khách hàng của một cửa hàng online có nhiều vấn đề về chất lượng dữ liệu. Hãy áp dụng tất cả kiến thức đã học để làm sạch và chuẩn bị dữ liệu.\n",
    "\n",
    "**Các bước thực hiện:**\n",
    "\n",
    "1. **Tạo dữ liệu mẫu** có chứa tất cả các vấn đề:\n",
    "   - Dữ liệu thiếu ở nhiều cột\n",
    "   - Dữ liệu trùng lặp\n",
    "   - Chuỗi ký tự không đồng nhất\n",
    "   - Dữ liệu phân loại cần encoding\n",
    "   - Dữ liệu số có outliers cần scaling\n",
    "\n",
    "2. **Phân tích và báo cáo** tình trạng dữ liệu ban đầu\n",
    "\n",
    "3. **Áp dụng các kỹ thuật làm sạch** đã học theo thứ tự phù hợp\n",
    "\n",
    "4. **So sánh và đánh giá** kết quả trước/sau khi xử lý\n",
    "\n",
    "5. **Xuất dữ liệu sạch** sẵn sàng cho phân tích/machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Tạo dữ liệu mẫu có nhiều vấn đề\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Tạo dữ liệu khảo sát khách hàng có vấn đề\n",
    "data_khaosat = {\n",
    "    'ho_ten': ['  Nguyễn Văn A  ', 'TRẦN THỊ B', 'nguyễn văn a', '  Lê Văn C  ', 'Phạm Thị D', 'TRẦN THỊ B', 'Hoàng Văn E', None],\n",
    "    'tuoi': [25, None, 25, 35, None, 30, 28, 45],\n",
    "    'gioi_tinh': ['Nam', 'Nữ', 'nam', 'Nam', 'Nữ', 'Nữ', None, 'Nam'],\n",
    "    'thu_nhap': [15000000, 25000000, None, 35000000, 18000000, 25000000, 150000000, 22000000],  # 150M là outlier\n",
    "    'muc_do_hai_long': ['Rất hài lòng', 'Hài lòng', None, 'Bình thường', 'Không hài lòng', 'Hài lòng', 'Rất hài lòng', 'Hài lòng'],\n",
    "    'so_lan_mua_hang': [5, 3, 5, 12, None, 3, 20, 8],\n",
    "    'email': ['  nguyena@gmail.com  ', 'tranthib@YAHOO.COM', None, 'levanc@outlook.com', '', 'tranthib@yahoo.com', 'hoange@company.vn', 'invalid-email'],\n",
    "    'thanh_pho': ['Hà Nội', 'tp.hcm', 'Hà Nội', 'Đà Nẵng', 'TP.HCM', 'tp.hcm', None, 'Hải Phòng']\n",
    "}\n",
    "\n",
    "df_raw = pd.DataFrame(data_khaosat)\n",
    "print(\"=== DỮ LIỆU KHẢO SÁT KHÁCH HÀNG (RAW) ===\")\n",
    "print(df_raw)\n",
    "\n",
    "# Bước 2: Phân tích tình trạng dữ liệu ban đầu\n",
    "print(\"\\n=== PHÂN TÍCH DỮ LIỆU BAN ĐẦU ===\")\n",
    "\n",
    "# Bước 3: Áp dụng các kỹ thuật làm sạch\n",
    "\n",
    "# Bước 4: So sánh kết quả\n",
    "\n",
    "# Bước 5: Xuất dữ liệu sạch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
